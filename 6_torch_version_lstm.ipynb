{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import gc\n",
    "\n",
    "import torch as t\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 400 ms, sys: 6.92 s, total: 7.32 s\n",
      "Wall time: 7.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "label_1 = pd.read_csv('./data/train_preliminary/user.csv')\n",
    "label_2 = pd.read_csv('./data/train_semi_final/user.csv')\n",
    "label = pd.concat([label_1, label_2], axis=0).reset_index(drop=True)\n",
    "mats_train = []\n",
    "mats_test = []\n",
    "for col in tqdm(['creative_id', 'ad_id', 'advertiser_id', 'product_id', 'industry']):    \n",
    "    mats_train.append(np.load('./inputs_new/{}_inputs_train.npy'.format(col)))\n",
    "    mats_test.append(np.load('./inputs_new/{}_inputs_test.npy'.format(col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def get_logger(filename, verbosity=1, name=None):\n",
    "    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}\n",
    "    formatter = logging.Formatter(\n",
    "        \"[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s\"\n",
    "    )\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level_dict[verbosity])\n",
    "\n",
    "    fh = logging.FileHandler(filename, \"w\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__() \n",
    "        emb_outputs = []\n",
    "        \n",
    "        cols = ['creative_id', 'ad_id', 'advertiser_id', 'product_id', 'industry']\n",
    "        n_in = len(cols)\n",
    "        for i in range(n_in):\n",
    "            We = np.load('./w2v_256_120/{}_embedding_weight.npy'.format(cols[i]))\n",
    "            We = np.vstack([We, np.zeros(256)])\n",
    "            embed = nn.Embedding(num_embeddings=We.shape[0],embedding_dim=We.shape[1],padding_idx=len(We)-1, _weight=t.FloatTensor(We))\n",
    "            for p in embed.parameters(): \n",
    "                p.requires_grad=False\n",
    "            emb_outputs.append(embed)\n",
    "            \n",
    "        for i in range(n_in):\n",
    "            We = np.load('./w2v_128_60/{}_embedding_weight.npy'.format(cols[i]))\n",
    "            We = np.vstack([We, np.zeros(128)])\n",
    "            embed = nn.Embedding(num_embeddings=We.shape[0],embedding_dim=We.shape[1],padding_idx=len(We)-1, _weight=t.FloatTensor(We))\n",
    "            for p in embed.parameters(): \n",
    "                p.requires_grad=False\n",
    "            emb_outputs.append(embed)\n",
    "            del We\n",
    "            gc.collect()\n",
    "\n",
    "        self.encoders = nn.ModuleList(emb_outputs)\n",
    "        self.emb_drop = nn.Dropout(p=0.2)\n",
    "        self.lstm = nn.LSTM(input_size=(256+128)*5, hidden_size=384, num_layers=2, bias=True, batch_first=True, dropout = 0.2, bidirectional = True)\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Sequential(nn.Linear(384, n_cls))\n",
    "        self.fc_drop = nn.Dropout(p=0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, xs):\n",
    "        inp = [self.encoders[i](x) for i, x in enumerate(xs)] + [self.encoders[i + 5](x) for i, x in enumerate(xs)]\n",
    "        x = t.cat(inp, 2)\n",
    "        x = self.emb_drop(x)\n",
    "        x = self.lstm(x)[0]\n",
    "        x = self.max_pool(x)\n",
    "        x = t.max(x, dim=1)[0]\n",
    "        x = self.fc_drop(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradient(optimizer, grad_clip):\n",
    "    for group in optimizer.param_groups:\n",
    "        #print(group['params'])\n",
    "        for param in group['params']:\n",
    "            param.grad.data.clamp_(-grad_clip, grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(t.utils.data.Dataset):\n",
    "    def __init__(self, xs, y, shuffle=False):\n",
    "        self.xs = xs\n",
    "        self.y = y\n",
    "        self.size = len(xs[0])\n",
    "        self.shuffle = shuffle\n",
    "         \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        xs = [x[idx].astype(np.int64) for x in self.xs]\n",
    "        y = self.y[idx]\n",
    "        if self.shuffle and np.random.rand() < 0.8:\n",
    "            state = np.random.get_state()\n",
    "            for x in xs:\n",
    "                np.random.set_state(state)\n",
    "                np.random.shuffle(x)     \n",
    "        return xs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion):\n",
    "    t0 = time.time()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.train() \n",
    "    for i, (xs, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        xs = [t.LongTensor(x).cuda() for x in xs]\n",
    "        yp = model(xs)\n",
    "        loss = criterion(yp, t.LongTensor(y).cuda())\n",
    "        loss.backward()\n",
    "        clip_gradient(optimizer, 0.1)\n",
    "        optimizer.step()\n",
    "        yp = t.softmax(yp, 1)\n",
    "        yp = np.argmax(yp.detach().cpu().numpy(), axis=1)\n",
    "        y_pred.append(yp)\n",
    "        y_true.append(y)\n",
    "        print('process: [%d/%d]' % (i + 1, len(loader)), end='\\r')\n",
    "    y_true = np.hstack(y_true)\n",
    "    y_pred = np.hstack(y_pred)\n",
    "    score = accuracy_score(y_true, y_pred)\n",
    "    print('process: [%d/%d], score: %f, dtime: %ds' % (i + 1, len(loader), score, time.time()-t0), end='\\n')\n",
    "    return None\n",
    "\n",
    "def val(model, loader):\n",
    "    t0 = time.time()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    with t.no_grad():\n",
    "        for i, (xs, y) in enumerate(loader):\n",
    "            xs = [t.LongTensor(x).cuda() for x in xs]\n",
    "            yp = model(xs)\n",
    "            yp = t.softmax(yp, 1)\n",
    "            yp = np.argmax(yp.cpu().numpy(), axis=1)\n",
    "            y_pred.append(yp)\n",
    "            y_true.append(y)\n",
    "            print('process: [%d/%d]' % (i + 1, len(loader)), end='\\r')\n",
    "    model.train() \n",
    "    y_true = np.hstack(y_true)\n",
    "    y_pred = np.hstack(y_pred)\n",
    "    score = accuracy_score(y_true, y_pred)\n",
    "    print('process: [%d/%d], score: %f, dtime: %ds' % (i + 1, len(loader), score, time.time()-t0), end='\\n')\n",
    "    return y_pred, score\n",
    "\n",
    "def test(model, loader, y_test):\n",
    "    t0 = time.time()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    with t.no_grad():\n",
    "        for i, (xs,y) in enumerate(loader):\n",
    "            xs = [t.LongTensor(x).cuda() for x in xs]\n",
    "            yp = model(xs)\n",
    "            yp = t.softmax(yp, 1)\n",
    "            y_test[i*batch_size:(i+1)*batch_size] = yp.cpu().numpy()\n",
    "            print('process: [%d/%d]' % (i + 1, len(loader)), end='\\r')\n",
    "    model.train() \n",
    "    print('process: [%d/%d], dtime: %ds' % (i + 1, len(loader), time.time()-t0), end='\\n')\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 02:21:16,484][<ipython-input-8-63381bc11791>][line:11][INFO] fold 0 start training!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2820000 180000\n",
      "process: [2754/2754], score: 0.460372, dtime: 2410s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 03:02:51,277][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[0/20]\t score=0.48811\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.488106, dtime: 52s\n",
      "process: [977/977], dtime: 284s\n",
      "best score: 0.48811\n",
      "process: [2754/2754], score: 0.486878, dtime: 2410s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 03:48:38,116][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[1/20]\t score=0.49632\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.496322, dtime: 52s\n",
      "process: [977/977], dtime: 281s\n",
      "best score: 0.49632\n",
      "process: [2754/2754], score: 0.495043, dtime: 2360s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 04:33:32,198][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[2/20]\t score=0.49952\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.499522, dtime: 51s\n",
      "process: [977/977], dtime: 280s\n",
      "best score: 0.49952\n",
      "process: [2754/2754], score: 0.500259, dtime: 2359s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 05:18:23,453][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[3/20]\t score=0.50489\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.504889, dtime: 51s\n",
      "process: [977/977], dtime: 280s\n",
      "best score: 0.50489\n",
      "process: [2754/2754], score: 0.504568, dtime: 2408s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 06:04:05,192][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[4/20]\t score=0.50582\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.505817, dtime: 52s\n",
      "process: [977/977], dtime: 284s\n",
      "best score: 0.50582\n",
      "process: [2754/2754], score: 0.507410, dtime: 2414s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 06:49:57,170][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[5/20]\t score=0.50906\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.509061, dtime: 52s\n",
      "process: [977/977], dtime: 284s\n",
      "best score: 0.50906\n",
      "process: [2754/2754], score: 0.510412, dtime: 2413s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 07:35:48,330][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[6/20]\t score=0.50940\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.509400, dtime: 52s\n",
      "process: [977/977], dtime: 284s\n",
      "best score: 0.50940\n",
      "process: [2754/2754], score: 0.512707, dtime: 2413s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 08:21:39,316][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[7/20]\t score=0.50932\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.509317, dtime: 52s\n",
      "process: [2754/2754], score: 0.514579, dtime: 2414s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 09:02:46,832][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[8/20]\t score=0.51021\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.510211, dtime: 52s\n",
      "process: [977/977], dtime: 284s\n",
      "best score: 0.51021\n",
      "process: [2754/2754], score: 0.516760, dtime: 2412s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 09:48:36,869][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[9/20]\t score=0.50977\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.509772, dtime: 52s\n",
      "process: [2754/2754], score: 0.518401, dtime: 2412s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 10:29:41,782][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[10/20]\t score=0.51193\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.511928, dtime: 52s\n",
      "process: [977/977], dtime: 285s\n",
      "best score: 0.51193\n",
      "process: [2754/2754], score: 0.521043, dtime: 2413s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 11:15:33,019][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[11/20]\t score=0.51147\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.511472, dtime: 52s\n",
      "process: [2754/2754], score: 0.523329, dtime: 2412s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 11:56:38,499][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[12/20]\t score=0.51272\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.512722, dtime: 52s\n",
      "process: [977/977], dtime: 284s\n",
      "best score: 0.51272\n",
      "process: [2754/2754], score: 0.525711, dtime: 2413s\n",
      "process: [176/176]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-20 12:42:29,171][<ipython-input-8-63381bc11791>][line:34][INFO] Epoch:[13/20]\t score=0.51402\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: [176/176], score: 0.514017, dtime: 52s\n",
      "process: [977/977], dtime: 284s\n",
      "best score: 0.51402\n",
      "process: [2294/2754]\r"
     ]
    }
   ],
   "source": [
    "tmp_data = pd.read_csv('./data/train_preliminary/user.csv')\n",
    "y = label['age'].values-1\n",
    "n_cls = 10\n",
    "batch_size = 1024\n",
    "y_test = np.zeros([mats_test[0].shape[0], n_cls])\n",
    "loader_te = DataLoader(Dataset(mats_test, np.zeros(mats_test[0].shape[0])), batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "kfold = StratifiedKFold(n_splits=5,random_state=2020)\n",
    "best_scores = []\n",
    "logger = get_logger('./torch1.log')\n",
    "for i, (idx_trn, idx_val) in (enumerate(kfold.split(tmp_data, tmp_data['age']))):  \n",
    "    logger.info('fold {} start training!'.format(i))\n",
    "    all_idx = np.arange(len(mats_train[0]))\n",
    "    subtraction = list((set(all_idx).difference(set(idx_val))))\n",
    "    x_test = np.zeros([mats_test[0].shape[0], n_cls])\n",
    "    x_trn = [x[subtraction] for x in mats_train]\n",
    "    x_val = [x[idx_val] for x in mats_train]\n",
    "    print(len(x_trn[0]), len(x_val[0]))\n",
    "    y_trn, y_val = y[subtraction], y[idx_val]\n",
    "#     x_trn = [mat[idx_trn] for mat in mats_train]\n",
    "#     x_val = [mat[idx_val] for mat in mats_train]\n",
    "#     y_trn, y_val = y[idx_trn], y[idx_val]\n",
    "    model = LSTM().cuda()\n",
    "    optimizer = t.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = 0.001)\n",
    "    scheduler = t.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loader_trn = DataLoader(Dataset(x_trn, y_trn, shuffle=True), batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    loader_val = DataLoader(Dataset(x_val, y_val), batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    best_score = 0.0\n",
    "    for i in range(20):\n",
    "        if i > 10:\n",
    "            scheduler.step()\n",
    "        train(model, loader_trn, optimizer, criterion)\n",
    "        result, score = val(model, loader_val)\n",
    "        logger.info('Epoch:[{}/{}]\\t score={:.5f}\\t'.format(i , 20, score))\n",
    "        if score > best_score:\n",
    "            x_test = test(model, loader_te, x_test)\n",
    "            best_score = score\n",
    "            print('best score: %.5f' % score)\n",
    "    best_scores.append(best_score)\n",
    "    y_test += x_test\n",
    "print('best scores:', best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./age_res/torch_lstm6_test_pred.npy', y_test/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.000000044241041"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_py3",
   "language": "python",
   "name": "conda_pytorch_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
